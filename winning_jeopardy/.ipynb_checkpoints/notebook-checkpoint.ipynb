{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings in Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd # Data processing\n",
    "import numpy as np # Linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import timeit # measure runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = [name.strip() for name in data.columns] # remove whitespaces in column names\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Question\"] = (\n",
    "    data[\"Question\"].str.replace(r\"\\W\",\" \")\n",
    "    .str.lower()\n",
    ")\n",
    "data[\"Answer\"] = (\n",
    "    data[\"Answer\"].str.replace(r\"\\W\",\" \")\n",
    "    .str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>for the last 8 years of his life  galileo was ...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>no  2  1912 olympian  football star at carlisl...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>in 1963  live on  the art linkletter show   th...</td>\n",
       "      <td>mcdonald s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>signer of the dec  of indep   framer of the co...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  for the last 8 years of his life  galileo was ...  copernicus  \n",
       "1  no  2  1912 olympian  football star at carlisl...  jim thorpe  \n",
       "2  the city of yuma in this state has a record av...     arizona  \n",
       "3  in 1963  live on  the art linkletter show   th...  mcdonald s  \n",
       "4  signer of the dec  of indep   framer of the co...  john adams  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Value\"] = (\n",
    "    data[\"Value\"].str.replace(\"$\",\"\")\n",
    "    .str.replace(\",\",\"\")\n",
    ")\n",
    "data[\"Value\"].loc[data[\"Value\"].str.contains(r\"[a-z]\")] = 0 # replace string values without numbers to 0\n",
    "data[\"Value\"] = data[\"Value\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Air Date\"] = pd.to_datetime(data[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we deduce answers from the asked questions?\n",
    "- Create a function that takes in a row and:\n",
    "    - splits the words in the `Question` column\n",
    "    - splits the words in the `Answer` column\n",
    "    - counts the number of word matches in both `Question` and `Answer`\n",
    "    - return match counts\n",
    "- Apply the created function to the dataframe `data` and create a column with the match counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of word counts that appear in both answer and question: 0.10\n"
     ]
    }
   ],
   "source": [
    "def match_counts(row):\n",
    "    split_question = row[\"Question\"].split(\" \")\n",
    "    split_answer = row[\"Answer\"].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\") # we do not want to match \"the\", irrelevant word\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer) # convert to ratio between 0 and 1\n",
    "\n",
    "data[\"answer_in_question\"] = data.apply(match_counts, axis=1)\n",
    "\n",
    "print(\"Mean of word counts that appear in both answer and question: {:.2f}\".format(data[\"answer_in_question\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the number of words that are part of the question and the answer as a probability. In almost 1 out of 10 questions (p = 0.10) part of the answer will be also part of the question. In these cases, we could be able to use the question to deduce the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are past questions recycled / repeated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of relevant word count ratios that have been repeated: 0.72\n"
     ]
    }
   ],
   "source": [
    "question_overlap = list()\n",
    "terms_used = set()\n",
    "data_sorted = data.sort_values(by=\"Air Date\")\n",
    "\n",
    "for index, row in data_sorted.iterrows():\n",
    "    split_question = row[\"Question\"].split()\n",
    "    split_question = [word for word in split_question if len(word) >= 6] # only consider words with 6 or more characters\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count +=1\n",
    "        else:\n",
    "            terms_used.add(word)\n",
    "    if len(split_question) > 0: \n",
    "        match_count = match_count / len(split_question) # convert to ratio between 0 and 1\n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "data_sorted[\"question_overlap\"] = question_overlap\n",
    "print(\"Mean of relevant word count ratios that have been repeated: {:.2f}\".format(data_sorted[\"question_overlap\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a high amount of words with more than 5 letters that are repeated in previous questions. The result shown above shows that there is a p = 0.72 of having repeated words in our questions. However, this does not mean that the question itself is being recycled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying high / low value questions\n",
    "We will use a chi-squared test to determine which terms used correspond to high or low value questions.\n",
    "- Low value: less than 800\n",
    "- High value: more than 800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_or_low(row):\n",
    "    if row[\"Value\"] > 800:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data_sorted[\"high_value\"] = data_sorted.apply(high_or_low,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the word counts for high and low value questions\n",
    "\n",
    "We will create a function that:\n",
    "- Takes in a word from the set terms_used\n",
    "- Assign high_count = 0 and low_count = 0\n",
    "- Loops through all the rows of data_sorted and, if the term is found, adds 1 to high_count or low_count\n",
    "- returns high_count, low_count\n",
    "\n",
    "We will then store these values in a dictionary, using the terms as keys and storing (high_count,low_count) as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'switzerland': (3, 7),\n",
       " 'flimsy': (0, 1),\n",
       " 'flashbacks': (1, 0),\n",
       " 'phenom': (0, 2),\n",
       " 'ratings': (0, 1)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = dict()\n",
    "\n",
    "def counts_high_low(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in data_sorted.iterrows():\n",
    "        if term in row[\"Question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "for term in list(terms_used)[:5]: # using only 5 terms to test our function\n",
    "    word_counts[term] = counts_high_low(term)\n",
    "    \n",
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'switzerland': Power_divergenceResult(statistic=0.008630851497838939, pvalue=0.9259811180040979),\n",
       " 'flimsy': Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " 'flashbacks': Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " 'phenom': Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " 'ratings': Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "chi_squared = dict()\n",
    "\n",
    "high_value_count = data_sorted[data_sorted[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = data_sorted[data_sorted[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "for key,value in word_counts.items():\n",
    "    total = sum(value)\n",
    "    total_prop = total / len(data_sorted)\n",
    "    high_expected = total_prop * high_value_count\n",
    "    low_expected = total_prop * low_value_count\n",
    "    observed = np.array([value[0],value[1]])\n",
    "    expected = np.array([high_expected,low_expected])\n",
    "    chi_squared[key] = chisquare(observed,expected)\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "From the 5 words analyzed, the only one with enough frequencies to apply a chi-squared test is the word reports. If we do not have high frequencies (4 of the 5 words have frequencies from 1 to 5), our chi-squared is not going to provide valid results.\n",
    "\n",
    "We could still try to find the words with the highest frequencies and apply the chi-squared test to only those terms and see if we can find any patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do:\n",
    "- Write intro/intent of this analysis and describe steps\n",
    "- Examine different ways to eliminate words that do not provide any information -i.e. eliminate words that occur too often in the questions\n",
    "- Do a chi-squared test on high frequency terms\n",
    "- Analyze the Category column and find any correlation with high/low value questions\n",
    "- Use more jeopardy data: Can be found [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)\n",
    "- Use phrases to analyze patterns in questions instead of splitting into words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
